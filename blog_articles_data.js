const articlesContent = {
  1: {
    title: 'Acculturer à l\'IA en santé : réussir le passage à l\'échelle',
    content: `Vous avez testé ChatGPT. Vos équipes aussi — parfois sans vous le dire. Et maintenant ? Comment passer du gadget individuel à la compétence collective, sans perdre le terrain en route ?

C'est LA question que se posent aujourd'hui les directions d'établissements de santé et médico-sociaux. Et la réponse ne se trouve ni dans un outil miracle, ni dans une formation « one shot » de deux heures.

L'enjeu n°1 n'est pas l'outil : c'est l'appropriation

Soyons clairs : les établissements qui investissent dans l'IA ne cherchent pas à « faire des économies » à court terme. Les données du baromètre FHF sont limpides : les bénéfices attendus se concentrent sur l'efficacité opérationnelle (80%), la qualité des soins (67%) et la satisfaction des équipes et des patients (42%).

Ce signal est précieux. Il dit une chose simple : l'IA est attendue comme un levier de temps utile — du temps rendu au soin, à l'écoute, à la coordination. Pas comme un gadget de plus dans un SI déjà surchargé.

Mais cette promesse ne se réalise qu'à une condition : que l'IA soit maîtrisée et intégrée aux pratiques. Pas déployée « à côté ».

Former « en masse » : la fausse bonne idée du one-shot

Vous connaissez le scénario. Une formation de sensibilisation, un pic d'enthousiasme (« c'est génial, ça va tout changer ! »), puis une phase de désillusion (« en fait, pour mon travail, c'est pas si simple… »), et enfin le retour aux habitudes. Ou pire : le Shadow IT, avec des usages non cadrés sur des comptes personnels.

Le problème n'est pas la pédagogie. C'est l'absence de trajectoire.

Le modèle qui fonctionne : 3 paliers, 90 jours, 1 règle d'or

La règle d'or d'abord : pas d'IA sans garantie humaine (validation explicite) et sans règles claires de confidentialité. Les cadres institutionnels — ANAP, HAS, CNIL — convergent tous sur ce point : l'IA doit s'inscrire dans une gouvernance, avec transparence et contrôle.

Palier 1 — « Hygiène & réflexes » (Semaines 1-2)

Objectif : éviter les erreurs irréversibles.`
  },
  2: {
    title: 'Fonctions support : où l\'IA crée de la valeur dès maintenant',
    content: `Quand on parle d'IA en santé, l'imaginaire va spontanément vers le diagnostic assisté, l'imagerie médicale, la médecine personnalisée. Des sujets passionnants — mais souvent lointains pour un directeur d'EHPAD, un DAF de clinique ou une responsable qualité en ESSMS.

Or le gisement de valeur immédiat est ailleurs. Il est dans ces heures passées à rédiger des comptes rendus, à compiler des rapports, à répondre aux tutelles, à mettre à jour des procédures. Bref : dans les fonctions support.

Ce que montrent les études : une « nouvelle frontière » de productivité

Les synthèses internationales convergent : l'IA générative peut automatiser une part importante des activités à forte intensité documentaire — rédaction, synthèse, extraction d'information, mise en forme. Et transformer la performance des fonctions support.

À une condition : cadrer, superviser, intégrer. L'IA n'est pas un stagiaire autonome. C'est un multiplicateur cognitif sous supervision humaine.

Cartographie : 6 fonctions, 18 cas d'usage « prêts terrain »

Direction & gouvernance

Briefs décisionnels : synthèse 1 page à partir de 50 pages de documents

Compte rendu CODIR structuré : décisions / actions / risques

Veille stratégique automatisée : réglementation, concurrence, innovation

Qualité & gestion des risques

Préparation certification HAS : plan, preuves, éléments de langage

Analyse des réclamations et EIG : thèmes récurrents, causes racines, plans d'action

Mise à jour des procédures : reformulation, cohérence, versioning

Ressources humaines

Fiches de poste conformes FPH/ESPIC : structure + compétences + contexte

Trames d'entretien et synthèses : objectifs, points d'appui, axes de progrès

Communication RH : FAQ interne, parcours d'intégration, notes de service

Finance & contrôle de gestion

Analyse d'écarts budgétaires : narratif + hypothèses + actions correctives

Préparation reporting : draft + slides + messages clés

Vulgarisation budgétaire : lecture « pédagogique » pour non-financiers`
  },
  3: {
    title: 'Licences IA, API, coûts cachés : reprendre le contrôle avant l\'explosion',
    content: `Combien d'outils IA sont utilisés dans votre établissement aujourd'hui ? Si vous répondez « 2 ou 3 », vous sous-estimez probablement d'un facteur 5. ChatGPT personnel, Claude sur téléphone, Copilot en test, outil de transcription « gratuit », extension de navigateur…

L'IA générative a une caractéristique redoutable : elle est tellement facile d'accès qu'elle se diffuse sans vous.

Le vrai coût de l'IA n'est pas le prix facial

Une licence à 20€/mois/utilisateur, ça paraît raisonnable. Mais le coût total, c'est autre chose :

Licences (souvent multipliées par le nombre d'outils « testés »)

Intégration (temps DSI, paramétrage, SSO)

Sécurité (DLP, logs, audits, procédures)

Formation (pas une fois : en continu)

Support (questions, incidents, évolutions)

Gouvernance (comités, arbitrages, mises à jour)

Risques (incident de données, erreur de contenu, perte de confiance)

Et surtout : le temps « invisible » — paramétrage, vérification, rework quand l'IA se trompe.

Shadow IA : le signal d'alarme

Les études sont sans appel : environ 68% des salariés utilisant l'IA générative au travail le font sans en informer leur employeur. En santé et médico-social, c'est immédiatement un sujet de confidentialité, de traçabilité et de conformité.

Le Shadow IA n'est pas un problème de « mauvaise volonté ». C'est un symptôme : le terrain a un besoin réel, et l'organisation n'y répond pas assez vite.

Les 5 sources d'explosion budgétaire

Empilement de licences : tout le monde « teste » tout

Licences inutilisées : pas de routine = pas d'usage

API non gouvernées : consommation variable, dérives

Support & sécurité : DLP, logs, audits, procédures

Coût du risque : incident de données, erreur de contenu, crise de confiance

Le playbook : rationaliser en 30 jours

Étape 1 — Inventaire des usages (pas des outils)

Ne demandez pas « quels outils utilisez-vous ? » mais « quelles tâches faites-vous avec l'IA ? ». Pour chaque usage : fréquence, données manipulées, bénéfice attendu.

Étape`
  },
  4: {
    title: 'Gateway IA : l\'infrastructure manquante pour démocratiser l\'IA en santé',
    content: `L'IA arrive dans vos établissements comme un « nuage d'outils » : licences individuelles, comptes personnels, essais dispersés, documents copiés-collés un peu partout. Résultat : adoption inégale, risques non maîtrisés, coûts invisibles.

Un gateway IA est une réponse structurante. C'est une couche centrale qui orchestre l'accès aux modèles, applique des règles de sécurité, trace les usages et standardise les pratiques. L'équivalent d'une « porte d'entrée » officielle à l'IA.

Le problème réel : dispersion + opacité

Sans dispositif transverse, vous obtenez :

Des comptes personnels (ChatGPT, Claude…)

Des exports sauvages (documents copiés vers des outils non validés)

Des prompts non conformes (données sensibles dans le cloud)

Des traces inexistantes (impossible d'auditer)

Des modèles différents selon les équipes (incohérence)

Vous finissez par gérer l'IA comme le Shadow IT… mais avec des enjeux bien plus élevés en santé.

Ce qu'un gateway IA apporte (version décideur)

Six fonctions essentielles :

SSO / authentification : un accès maîtrisé (qui utilise quoi)

Routing : choix du modèle selon le cas (productivité / spécialisé / souverain)

DLP & filtres : prévention de sortie de données sensibles

Logs : traçabilité complète (audit, incidents, conformité)

Catalogue d'usages : bibliothèque de prompts et gabarits validés

Mesure : adoption, volumétrie, coûts, gains — pilotage par la valeur

En résumé : ça transforme l'IA d'un « ensemble d'essais » en capacité organisationnelle.

Pourquoi c'est particulièrement pertinent en santé ?

Données sensibles + exigence de confiance

Les référentiels santé (ANAP, HAS, CNIL) insistent sur la supervision humaine, l'information du patient et la traçabilité. L'IA générative peut produire des textes pertinents… ou erronés. La prudence est de mise.

Adoption à grande échelle = besoin de standardiser

Les établissements attendent de l'IA qu'elle libère du temps « non médical ». Mais sans standardisation (prompts, méthodes de vér`
  },
  5: {
    title: 'IA en santé : sécurité, confidentialité, souveraineté — et pourquoi l\'hybride devient la norme',
    content: `Les acteurs institutionnels sont clairs : l'IA doit s'intégrer aux pratiques « toujours au bénéfice de la relation de soin ». Sa réussite repose sur une évaluation continue, une adaptation au terrain, et l'implication des professionnels.

Dans ce contexte, trois exigences structurent les décisions. Et un choix architectural revient de plus en plus : l'approche hybride.

Confidentialité : la question n°1 n'est pas « quel outil » mais « quelles données »

En santé, la donnée est sensible par nature. Et l'IA générative ajoute une difficulté : elle peut produire des contenus convaincants mais pas nécessairement vrais — d'où la nécessité de validation humaine systématique.

Les guides pratiques rappellent une logique simple : dès qu'il y a données de santé et finalité de soin, on entre dans des obligations fortes (RGPD + HDS + information du patient). L'établissement doit pouvoir expliquer le rôle de l'IA et garantir une supervision humaine.

Règle opérationnelle : classez vos usages par niveau de sensibilité des données, puis choisissez l'architecture.

Sécurité : la surface d'attaque augmente avec la multiplication des outils

Le problème ne vient pas que des IA « médicales ». Il vient surtout des usages dispersés : comptes personnels, extensions de navigateur, outils de transcription non cadrés, dépôts de documents sur des services non autorisés.

Les recommandations opérationnelles sont claires :

Impliquer DPO/RSSI/DSI dans le cadrage

Choisir un hébergement et des mécanismes de contrôle adaptés

Mettre en place journalisation et traçabilité

Conduire le changement (pour éviter les contournements)

Souveraineté : pas un slogan, une capacité

La souveraineté, dans la vraie vie d'un hôpital, se traduit par des questions pragmatiques :

Où sont traitées les données ?

Quels sous-traitants ?

Quelle réversibilité ?

Quels journaux d'accès ?

Quelle capacité à continuer si le fournisseur change ses règles, ses prix, ou ses conditions ?

Le numérique n'est pas neutre : ce`
  },
  6: {
    title: 'ROI de l\'IA en santé : ce qui est mesurable, ce qui est illusoire, et comment trancher',
    content: `Quand vous présentez un projet IA à votre direction ou à votre tutelle, la question tombe toujours : « Et le ROI ? » C'est normal. C'est même sain. Mais c'est aussi un terrain miné.

Car en santé, le ROI est multidimensionnel. Le baromètre FHF est clair : l'optimisation des coûts n'est pas l'objectif n°1. Elle arrive après l'efficacité, la qualité et la satisfaction. C'est un signal fort.

Les gains les plus robustes : là où il y a du texte et des routines

Les retours d'expérience en milieu hospitalier et médico-social indiquent des gains quand l'IA est bien intégrée :

Productivité administrative (CR, synthèses, reporting)

Codage et valorisation

Aide au diagnostic et à la décision (avec supervision)

Côté fonctions support, les gains portent sur la rédaction, la synthèse, la veille, le reporting — à condition de mettre en place méthode et garde-fous.

Les mythes classiques

Mythe 1 : une licence = un gain

Faux. Une licence sans usage outillé = adoption faible, gains nuls.

Mythe 2 : l'IA remplace le travail

En santé, elle augmente et redistribue. La garantie humaine reste indispensable.

Mythe 3 : on peut mesurer le ROI en 2 semaines

Souvent faux. Il faut une période d'apprentissage et une comparaison rigoureuse.

La méthode pour mesurer (simple et défendable)

Étape A — Définir 3 indicateurs par cas d'usage

Temps (minutes par tâche)

Qualité (taux de correction, conformité, erreurs)

Satisfaction (utilisateur, patient, équipe)

Étape B — Mesurer avant/après sur un échantillon

10 personnes × 5 tâches × 2 semaines (avant). Même protocole (après), même périmètre.

Étape C — Intégrer la « valeur santé »

Pas seulement le coût. Aussi : temps soignant rendu, délai de réponse tutelles, qualité documentaire, prévention d'incidents.

ROI « social » vs ROI « financier »

Certains projets ont un ROI financier direct (recouvrement, optimisation planning). D'autres ont un ROI « social » (qualité du soin, QVT, attractivité).

En santé et médico-social, le ROI doit souve`
  },
  7: {
    title: 'Shadow IA : le vrai sujet n\'est pas l\'interdiction… c\'est l\'alternative',
    content: `Vos équipes utilisent déjà l'IA. La question n'est pas « si » mais « comment » — et surtout « avec quelles données ».

Les études sont sans appel : environ 68% des salariés utilisant l'IA générative au travail le font sans en informer leur employeur. En santé et médico-social, ce n'est pas un détail : c'est un risque de confidentialité et de conformité.

Pourquoi le Shadow IA explose en santé ?

Charge documentaire forte (CR, synthèses, procédures)

Manque de temps chronique

Outils grand public efficaces et gratuits

Manque de cadre interne (ou cadre trop lent à arriver)

Besoin d'aide immédiate — pas dans 9 mois

Le Shadow IA n'est pas un problème de « mauvaise volonté ». C'est un symptôme : le terrain a un besoin réel, et l'organisation n'y répond pas.

Le triptyque des risques

Données

Copier-coller de données sensibles vers des outils non maîtrisés.

Fiabilité

Hallucinations : des textes plausibles mais faux, sans vérification.

Traçabilité

Impossible d'auditer l'usage, de savoir ce qui a été produit avec l'IA.

La mauvaise réponse : « interdire et espérer »

Interdire sans alternative crée :

Des contournements (comptes personnels)

Une perte de confiance (« la direction ne comprend pas »)

Un retard croissant vs. les établissements qui avancent

La bonne réponse : canaliser.

La stratégie en 4 actions concrètes

1. Cartographier l'usage réel

Pas « qui a un abonnement » mais : quel cas d'usage, quelle donnée, quelle fréquence.

2. Mettre une règle simple et visible

Données identifiantes : interdit hors périmètre validé

Modèle/outil validé : liste courte et claire

3. Offrir une alternative « aussi simple »

Le gateway IA est une réponse : accès central, filtres, logs, bibliothèques de prompts.

4. Former à l'hygiène IA

Transparence, accompagnement, intégration dans la trajectoire de l'établissement.`
  },
  8: {
    title: 'Hygiène IA : 12 réflexes non négociables pour un usage professionnel',
    content: `L'hygiène IA, c'est l'ensemble des règles simples qui évitent les erreurs de base, les fuites de données et les usages « hors cadre ». Ce n'est pas spectaculaire — mais c'est ce qui rend tout le reste possible.

Les 4 principes de base

1. Garantie humaine

L'humain garde le dernier mot. En santé, la supervision humaine n'est pas une option : elle est structurante dans tous les référentiels de « déploiement de confiance ».

2. Moins de données = moins de risques

On ne met que ce qui est nécessaire à la tâche. Jamais « tout le dossier ».

3. Traçabilité

Pouvoir expliquer comment on a produit le document ou la recommandation. Si une IA a contribué, c'est une question de redevabilité, pas de morale.

4. Interopérabilité

Un outil utile ne doit pas créer 3 ressaisies derrière. Le temps gagné peut être perdu ailleurs si l'IA est ajoutée comme un silo.

Les 12 réflexes « terrain »

À diffuser à toutes vos équipes — et à intégrer dans votre charte interne :

Je n'entre jamais de données patient identifiantes dans un outil non validé

Je considère chaque résultat IA comme un brouillon : je vérifie et je corrige

Je demande un format contrôlable : plan, tableau, check-list, avec hypothèses explicites

Je fais préciser les sources ou je fournis moi-même les documents autorisés

Je « borne » la réponse : longueur, style, périmètre, exclusions

Je garde une trace : prompt + version + document final

Je sépare public / interne / sensible : trois niveaux, trois règles

J'utilise l'IA pour réduire la charge administrative, pas pour automatiser une décision sans relecture

J'évite l'illusion de compétence : si je ne comprends pas la sortie, je ne l'utilise pas

Je signale les dérives : hallucinations, biais, réponses dangereuses

Je travaille en « boucle courte » : itérations, tests, amélioration continue

Je connais la procédure dégradée (si l'outil tombe, si le réseau est indisponible)

Exemple concret : un « bon » prompt de compte-rendu

Le but n'est pas de faire un prompt « b`
  },
  9: {
    title: 'Gouverner l\'IA en santé : comitologie légère, rôles clairs, décisions traçables',
    content: `« Garder la maîtrise » de l'IA, c'est évaluer avec exigence, questionner les usages, garantir l'utilité réelle pour les équipes et les patients. C'est ce que rappellent tous les acteurs institutionnels — FHF, ANAP, HAS.

Mais gouverner ne veut pas dire bureaucratiser. L'objectif est d'avoir une comitologie légère qui permet de décider vite et bien.

Les 5 décisions structurantes

Pourquoi l'IA ? Objectifs : temps, qualité, satisfaction — pas uniquement coûts

Où l'IA s'applique ? Usages prioritaires, périmètre clair

Avec quelles données ? Classification + règles

Avec quel contrôle humain ? Garantie humaine opérationnelle

Comment on mesure ? KPIs, incidents, adoption, ROI

La comitologie « légère » qui marche

L'ANAP recommande d'intégrer le pilotage IA dans les comités existants (COPIL projets, innovation, SI) plutôt que de créer une usine à gaz.

En pratique :

COPIL IA mensuel (45 minutes) : DG/DSI/RSSI/DPO + métiers (qualité/RH/soins)

Référents IA par direction/filière (les « champions »)

Registre IA : inventaire des IA utilisées (outil, finalité, données, risques, responsable)

La charte IA (1 page) : contenu minimal

Ce que l'on cherche (la valeur attendue)

Ce que l'on refuse (données, décisions automatisées sans humain)

Les règles de confidentialité

Les règles de vérification (hallucinations)

Les modalités d'audit et de traçabilité

Le « chemin officiel » pour proposer un nouveau cas d'usage

La « garantie humaine » : de la théorie à l'opérationnel

On la traduit en 3 temps :

Avant

Validation du cas d'usage, test, procédure documentée.

Pendant

Supervision dans l'usage réel, double vérification sur les contenus sensibles.

Après

Revue d'incidents, amélioration continue, retrait si nécessaire.`
  },
  10: {
    title: 'Apprendre l\'IA avec l\'IA : le parcours 30 jours qui transforme un utilisateur en praticien',
    content: `Comment faire monter en compétence 50, 100 ou 500 collaborateurs sur l'IA sans mobiliser des semaines de formation ? La réponse est dans un parcours progressif, ancré dans la pratique quotidienne.

Voici un programme de 30 jours, testable immédiatement.

Semaine 1 — Comprendre & sécuriser (les fondamentaux)

Objectifs :

Comprendre comment l'IA génère (probabilités, limites)

Connaître les erreurs typiques (hallucinations)

Connaître la règle « données interdites »

Exercices (15 min/jour) :

Demander à l'IA d'expliquer un concept, puis le reformuler soi-même

Demander à l'IA de produire un plan, puis l'améliorer

Demander à l'IA de lister ses incertitudes (« ce que tu ne sais pas »)

Semaine 2 — Prompts métier (productivité immédiate)

Objectif : 5 cas d'usage utiles tout de suite

Compte-rendu de réunion

Synthèse de document

Mail structuré (ARS / familles / interne)

Fiche de poste

Check-list qualité

On crée une bibliothèque personnelle de prompts — copiable dans un wiki interne.

Semaine 3 — Vérification & qualité

Objectifs :

Apprendre à « auditer » une réponse IA

Exiger les sources / justifications

Repérer incohérences, biais, oublis

L'IA peut aider : « trouve les failles de ce texte », « liste les hypothèses implicites », « propose un plan de contrôle ».

Semaine 4 — Passage à l'échelle (dans l'équipe)

Objectifs :

Partager 10 prompts validés

Définir les règles de l'équipe

Mesurer un gain simple (avant/après)

La logique rejoint celle de l'ANAP : conduite du changement et intégration aux pratiques sont indispensables.`
  },
  11: {
    title: 'Accès aux droits à l\'ère de l\'IA : éviter le non-recours numérique',
    content: `L'enthousiasme pour l'IA ne doit pas faire oublier une réalité : tout le monde n'est pas à l'aise avec le numérique. Et dans le secteur santé-social, les publics les plus fragiles sont souvent ceux qui ont le plus besoin d'accompagnement.

Les 3 risques majeurs

Le guichet unique numérique

Si l'IA devient le seul point d'entrée, sans alternative humaine, on exclut mécaniquement une partie du public.

L'opacité

Des usagers qui ne comprennent pas pourquoi une décision a été prise, pourquoi un dossier a été orienté d'une certaine façon.

Les biais

Des algorithmes qui, sans le vouloir, pénalisent certains profils — les publics fragiles en première ligne.

Le CESE propose d'instaurer un « droit au non-numérique » pour éviter l'exclusion. En santé, c'est un sujet opérationnel, pas philosophique.

Comment faire « IA inclusive » concrètement

Maintenir un canal humain (présentiel, téléphone) — toujours

Médiation numérique : aide à l'usage pour ceux qui en ont besoin

Langage clair + FALC (Facile à Lire et à Comprendre) quand nécessaire

Transparence : informer du rôle de l'IA, expliquer, donner un recours

Les cas d'usage utiles en santé et médico-social

Chatbots d'orientation vers les services (avec garde-fous et escalade humaine)

Traduction et simplification de documents (FALC)

Aide au remplissage de démarches (sans automatiser la décision finale)

Rappels proactifs (rendez-vous, renouvellements, droits à activer)`
  },
  12: {
    title: 'IA et inégalités : comment éviter une fracture professionnelle dans la santé',
    content: `On parle beaucoup de l'IA comme « grand égalisateur » — l'outil qui donne à chacun les capacités d'un expert. C'est parfois vrai. Mais c'est aussi parfois l'inverse : un accélérateur d'inégalités entre ceux qui maîtrisent et ceux qui décrochent.

Pourquoi le fossé se crée vite

Outils faciles à adopter individuellement (mais pas collectivement)

Formation inégale selon les services, les générations, les appétences

Shadow IT : certains avancent « en cachette », d'autres restent sur le bord

Absence de standards : chacun fait comme il peut

Les enquêtes montrent que l'usage clandestin est fréquent : une majorité des utilisateurs d'IA générative au travail ne le signale pas à l'employeur. Résultat : des écarts de productivité invisibles, mais réels.

Les 4 leviers anti-fracture

1. Socle commun

Hygiène IA + prompts métiers de base pour tous. Pas d'exception.

2. Mentorat

Des « champions » identifiés + du binômage entre utilisateurs avancés et débutants.

3. Outils officiels simples

Gateway, bibliothèque de prompts, canal support. Si l'alternative officielle est plus compliquée que ChatGPT personnel, elle ne sera pas utilisée.

4. Reconnaissance

Valoriser l'apprentissage, pas seulement la performance. Créer une culture où « apprendre l'IA » est encouragé, pas suspect.

Le point clé : l'IA doit redistribuer du temps « vers l'humain »

La FHF rappelle que l'objectif est de dégager du temps non médical pour le réinvestir dans le soin et la dimension humaine.

C'est aussi l'antidote à la fracture : montrer que l'IA augmente le collectif, pas une minorité de « geeks ». Que le temps gagné revient à ceux qui soignent, accompagnent, coordonnent.`
  },
  13: {
    title: 'IA et transformation des métiers en santé : ce qui change vraiment',
    content: `Le secteur santé-social fait face à une équation impossible : plus de besoins (vieillissement, maladies chroniques, santé mentale), moins de ressources (pénurie de soignants, contraintes budgétaires). L'IA n'est pas une solution magique — mais elle peut changer l'équation.

Ce que l'IA change dans les métiers

Les tâches qui se transforment

Documentation et reporting : génération assistée, mise en forme automatique

Recherche d'information : synthèse rapide de protocoles, réglementation, littérature

Communication : mails, courriers, notes — rédaction accélérée

Planification : aide à l'optimisation des plannings, simulations

Analyse : détection de patterns, alertes, aide à la décision

Les tâches qui restent humaines

La relation : écoute, empathie, présence

Le jugement clinique : diagnostic final, décision thérapeutique

L'éthique : arbitrages complexes, situations singulières

La coordination : négociation, médiation, leadership

L'IA prend en charge le « travail sur le travail » pour libérer du temps pour le cœur de métier.

Les nouvelles compétences à développer

Savoir formuler une demande à l'IA (prompting)

Savoir vérifier et corriger une sortie IA

Savoir articuler IA et expertise métier

Savoir identifier les limites et les risques

Savoir accompagner le changement dans son équipe

Ce ne sont pas des compétences « techniques » au sens informatique. Ce sont des compétences professionnelles augmentées.

Ce que les établissements doivent anticiper

GPEC et formation

Intégrer l'IA dans les référentiels de compétences et les plans de formation. Pas comme une option, mais comme un socle.

Redéploiement du temps

Si l'IA fait gagner 1h par jour à un cadre, que fait-on de cette heure ? La réponse doit être pensée en amont : temps de coordination, temps de présence, temps de projet.

Dialogue social

Associer les représentants du personnel à la réflexion. L'IA ne doit pas être perçue comme une menace, mais comme un outil au service des équipes.

Attractivité

L`
  },
};
